---
title: "A workflow for Allele-specific read counts"
output:
  html_document:
    theme: journal
    highlight: tango
    toc: true
    toc_depth: 3
    toc_float: 
      collapsed: true
      smooth_scroll: false
---

## Download SNP genotype array data from NCI GDC legacy archive
Download data files from NCI GDC legacy archive https://portal.gdc.cancer.gov/legacy-archive/search/f
  
  + choose a project  
  + Experimental Strategy is genotyping arrary, data category is simple nucleotide variation, data type is genotypes 
  + The TXT files end with birdseed.txt 
  + Download Manifest and Metadata, after adding all the files to the cart
  + option:
    * `-t` location of the token required to download controlled data 
    * `-m` path to the manifest file

```{bash, eval =F}
#!/bin/bash

/fh/fast/sun_w/bin/gdc-client download -n 4 \
-t gdc-user-token.2018-08-02T10_39_10-07_00.txt \
-m gdc_manifest_20180801_215718.txt

```

The Manifest file looks like:
```{r, eval =F}
manifest = read.table('/fh/fast/sun_w/licai/_tumor_eQTL/gdc_manifest_20180529_223406.txt',
                     sep = '\t', header = T)
head(manifest)
```

```
                                   id
1 000264e1-ef7e-4df8-9b3f-3d20af778417
2 000476b3-3aa4-4857-ad74-ab13eaea468b
3 0027d158-eab4-4590-9cd0-0d5a7f4af60e
4 002824cc-1cbe-4be0-ab88-176fcff56a63
5 00330f63-dc1a-447d-9a4d-c0b7df806ed5
6 00a2a84c-71bf-4433-913b-918d9ccceca4
                                                                      filename
1      BUBBY_p_TCGA_b89_105_SNP_N_GenomeWideSNP_6_B05_777516.birdseed.data.txt
2           KEYED_p_TCGAb41_SNP_N_GenomeWideSNP_6_D04_598754.birdseed.data.txt
3 HELVE_p_TCGA_b139_154_155_SNP_N_GenomeWideSNP_6_G09_808646.birdseed.data.txt
4           SONGS_p_TCGAb36_SNP_N_GenomeWideSNP_6_A07_585392.birdseed.data.txt
5       RARER_p_TCGA_MixedRedos_N_GenomeWideSNP_6_C05_747790.birdseed.data.txt
6         BAIZE_p_TCGA_b138_SNP_N_GenomeWideSNP_6_D12_808776.birdseed.data.txt
                               md5     size state
1 510c15b759e6fecb1711ae98f272c4f6 20850936  live
2 7363e3597a9c723d61370edd01daefbf 20850921  live
3 d4f5df3dddf5a77691bf4e34251e0774 20851974  live
4 14b3d959035d2dc5218424aaf89b0a8b 20850926  live
5 43a026908f0b66558339844b677d8647 20850929  live
6 78379b1eb28e7f691bdca34ffbffc2ca 20850930  live
```

## Step A: Prepare input data
### step 1: prepare genotype calls and convert them to ped and map format 
  + file required
    * genotype file from NCI GDC legacy 
    * JSON file (Metadata downloaded in the previous steps)
  +	Use Blood Derived Normal sample (sample type code: 10). If blood sample not exists, use solid tissue normal (sample type code: 11)
  + Ped format: http://zzz.bwh.harvard.edu/plink/data.shtml#ped
  + Map format: http://zzz.bwh.harvard.edu/plink/data.shtml#map 

### step 2: separate file by chromosome
Step 1 has prepared the genotype data files geno.map and geno.ped for all samples. We can using the following shell command to splilt it into each chromosome. 
```{bash, eval =F}
#!/bin/bash

mkdir -p chr
ml plink/1.90

for chr in $(seq 1 22); 
do
plink --file geno \
--chr $chr \
--recode \
--out ./chr/geno.chr$chr ;
done

```

After previous steps, the data should be the following format. The following data were simulated data for demonstration. 
```{r}
genotype_calls = read.table('../data/sample_geno_call_22.txt', 
                           header = T, as.is = T, sep ='\t')

geno.chr22.map = read.table('../data/chr/geno.chr22.map', 
                           header = F, as.is = T, sep ='\t')

geno.chr22.ped = read.table('../data/chr/geno.chr22.ped', 
                           header = F, sep ='\t')

genotype_calls[1:5,1:5]
head(geno.chr22.map)
geno.chr22.ped[1:5, 1:15]

```


## Step B: phasing and imputation

After step A, we will have following file structure. Due to limited storage, we showed part of them in the example data. 

```
project
└─── README.md
└─── data
    └─── chr
        └─── geno.chr22.map
        └─── geno.chr22.ped
        └─── ...
    └─── genotype_calls.txt
    └─── geno.map
    └─── geno.ped
    └─── clinical_meta.txt
└───code
    └─── stepA_prepare_input_data
    └─── stepB_phasing_and_imputation
    └─── stepC_collect_read_count
    └─── flow.txt
```

### step 1: Run shapeit in check model to check the missingness and mismatches of the PLINK as compared to 1000G reference. 
  + Download reference panel 1000G reference
  +	Option:
    * `--Check` – turn on check mode
    * `--input-ped` – chromosome level data in PED/MAP format
    * `--input-map` – recombination map for each chromosome from 1000G, see the folder below
    * `--input-ref` – requires chromosome level files with haplotypes, legends and sample info from 1000G, located in the same reference folder
    * `--output-log` – path to output log file

When filling in the required path to shapeit location, reference panel and input and output, R will generate bash script and automaticaly submit them The example for chromoson bash script should look like:

```{bash, eval =F}
#!/bin/bash
path_input='/fh/fast/sun_w/licai/_tumor_eQTL'

path_input/shapeit.v2.904.3.10.0-693.11.6.el7.x86_64/bin/shapeit -check \
--input-ped ../../data/chr/geno.chr22 \
--input-map path_input/1000GP_Phase3/genetic_map_chr22_combined_b37.txt \
--input-ref path_input/1000GP_Phase3/1000GP_Phase3_chr22.hap.gz \
path_input/1000GP_Phase3/1000GP_Phase3_chr22.legend.gz \ 
path_input/1000GP_Phase3/1000GP_Phase3.sample \
--output-log ../../data/chr/precheck_log/gwas.alignments_chr22

```

### step 2-4: flip the mismathed SNPs and check whether strand issue can be fixed
These steps essentially repeats what we did in step1. 

- step2: repeating step1, only with flipped SNPs that were declared inconsistent and compares whether the resulting lists of inconsistent SNPs differ 

- Step3: provides us with a simple chromosome-level statistic showing how many SNPs are to be excluded from our unphased data classified as missing/strand 

- Step4: flip the SNPs with strand issue and then repeat shapeit check mode 
  + plink: Flip strand: http://zzz.bwh.harvard.edu/plink/dataman.shtml#flip 


### Step 5: Run Shapeit (Phasing)
  + option: 
    *	`--exclude-snp` – this list was produced in step1 and we saw that it is not fixed by flipping the strand in step2
    *	`--O` – now we save phased data to the separate phasedR (phased with reference) folder giving a prefix for a file name that includes chromosome that is to be processed
    *	`--effective-size` 20000 – since we use 1000G  data, we don’t need to choose a smaller number for European population as it was described for HapMap, we will use the same value they recommend during imputation step
    *	`--seed 1234567` – some random seed for reproducibility of the run
    *	`--thread 6` – will speed calculations (number depends on how many cpu per core)

When filling in the required path to shapeit location, reference panel and input and output, R will generate bash script and automatically submit them and the example bash script should look like:

```{bash, eval =F}
#!/bin/bash
path_input='/fh/fast/sun_w/licai/_tumor_eQTL'

path_input/shapeit.v2.904.3.10.0-693.11.6.el7.x86_64/bin/shapeit \
--input-ped ../data/chr_flipped/KIRC.chr22_flip \
--input-map path_input/1000GP_Phase3/genetic_map_chr22_combined_b37.txt \
--input-ref path_input/1000GP_Phase3/1000GP_Phase3_chr22.hap.gz \
path_input/1000GP_Phase3/1000GP_Phase3_chr22.legend.gz \
path_input/1000GP_Phase3/1000GP_Phase3.sample \
--exclude-snp ../../data/chr_flipped/precheck_log/geno.chr22_flip_check.snp.strand.exclude \
-O ../../data/phased/phasing_chr22 \
--effective-size 20000 --seed 1234567 \
--thread 6 > ./log/step5_shapeit/shapeit_chr22.o 2> ./log/step5_shapeit/shapeit_chr22.e

```

### Step 6: Run impute2 (Imputation) 
  + option:
    *	`-use_prephased_g` – since we did phasing in step5
    * `-known_haps_g` – here we supply the output of the step5 phasing_chr1.log.haps
    *	`-m` – recombination map, the same as the one that was used in step1 from 1000G reference panel
    *	`-h` – haplotypes from the reference panel, the same as were used in step1
    *	`-l` – legends from the reference panel, the same as were used in step1
    *	`-align_by_maf_g` - activates the program's internal strand alignment procedure for our data
    *	`-Ne 20000` – controls the effective population size in the population-genetic model used by IMPUTE2 (When using these combined panels, you should set the -Ne argument of IMPUTE2 to 20000, https://mathgen.stats.ox.ac.uk/impute/data_download_1000G_phase1_integrated.html)
    *	`-seed 12345` – random seed set
    
The example bash script should look like:
```{bash, eval =F}
#!/bin/bash

path_input='/fh/fast/sun_w/licai/_tumor_eQTL'

path_input/impute_v2.3.2_x86_64_dynamic/impute2 \
-use_prephased_g -m path_input/1000GP_Phase3/genetic_map_chr22_combined_b37.txt \
-h path_input/1000GP_Phase3/1000GP_Phase3_chr22.hap.gz \
-l path_input/1000GP_Phase3/1000GP_Phase3_chr22.legend.gz  \
-known_haps_g ../data/phased/phasing_chr22.haps \
-align_by_maf_g -Ne 20000 -seed 12345 -int 16e6 21e6 -phase \
-o ../../data/imputed/phased_imputed_chr22_16e6_21e6 \
> ./log/step6_imputation/impute_chr22.o 2> ./log/step6_imputation/impute_chr22.e'

```


### Step 7 – 9 and step 12: Check shapeit/flipped/unflipped/imputed results corresponds to genotype array. 
In these steps, we check the results from step 6 and make sure the heterozygous SNPs remain heterozygous. 

  + step 7: shapeit versus genotype array
  + step 8: flipped versus genotype array
  + step 9: unflipped versus genotype array
  + step 12: imputed versus genotype array
  
### Step 10: get the most likely genotype. 
For each SNP, the genotype is set to be the most lilely one, if the most likely genotype having probability > 80%, otherwise it is set to be NA. 

For each chunk of a chromosome, we have 7 output files. 
```{r}
phased = "../data/phased"
inputdir = "../data/imputed"
list.files(inputdir)
```

For file format, see http://www.stats.ox.ac.uk/~marchini/software/gwas/file_format.html 

Example:  Suppose you want to create a genotype for 2 individuals at 5 SNPs whose genotypes are
```
        SNP 1:     AA    AA
        SNP 2:     GG    GT
        SNP 3:     CC    CT
        SNP 4:     CT    CT
        SNP 5:     AG    GG
```

The correct genotype file would be

```
        SNP1 rs1 1000 A C 1 0 0 1 0 0
        SNP2 rs2 2000 G T 1 0 0 0 1 0
        SNP3 rs3 3000 C T 1 0 0 0 1 0
        SNP4 rs4 4000 C T 0 1 0 0 1 0
        SNP5 rs5 5000 A G 0 1 0 0 0 1
```
So, at SNP3 the two alleles are C and T so the set of 3 probabilities for each indvidual correspond to the genotypes CC, CT and TT respectively. 

```{r, warning = F}
setwd(inputdir)
chri = 22
fls = list.files(pattern=sprintf("chr%s_",chri))
to.rm = union(union(union(grep(".txt",fls),grep("info_by_sample",fls)),grep("warnings",fls)),grep("summary",fls))
fls = fls[-to.rm]
hps = fls[grep("_haps",fls)]
alp = fls[grep("_allele_probs",fls)]
info = fls[grep("info$",fls)]
fls = setdiff(fls,union(union(hps,alp), info))

fls
snpj = read.table(fls,as.is=T)
snpj[1:5,1:8]

hps
hpj = read.table(hps,as.is=T)
hpj[1:5,1:7]

alp
alpj = read.table(alp,as.is=T)
alpj[1:5,1:8]

```

### Step 11: Get heterozygous SNP list. 
  We filter out SNP with R2 < 0.3  
  'info' is similar to the r-squared metrics reported by other programs like MaCH and Beagle

```{r}
setwd(inputdir)
info
infoj = read.table(info,as.is=T, header =T)
infoj[1:5,1:8]

```



### Step 13: lift to builder HG38
The snpfiles have to be lifted from HG19 to HG38 in order to be in line with bamfiles in Step C: collect read counts.

```{bash, eval =F}
#!/bin/bash
path_to_liftOver = "/fh/fast/sun_w/bin/liftOverLinux"

path_to_liftOver/liftOver combined.txt \
path_to_liftOver/hg19ToHg38.over.chain combined_hg38.txt combined_unlifted.txt
```


## Step C: Collect read counts

Download bam file from https://portal.gdc.cancer.gov/
  
  + Choose a project
  + Data Format is BAM, Experimental Strategy is RNA-Seq, and Data Category is Raw Sequencing Data

###	Step 1: make sqlite file 
  
  + Download most recent GENCODE from https://www.gencodegenes.org/releases/current.html 

```{r, eval = F}
library("GenomicFeatures")

proj_input = "/fh/fast/sun_w/licai/_tumor_eQTL"
gtfIn   = sprintf("%s/gencode.v28.annotation.gtf", proj_input)  # from GENCODE

txdb2 = makeTxDbFromGFF(file=gtfIn, format="gtf",
                        # dataSource=paste(path, file, sep=""),
                        organism="Homo sapiens")

saveDb(txdb2, file=sprintf("%s/Homo_sapiens_gencode_v28_GRCh38.sqlite", proj_input))

```

### Step 2: sort bam file
Sort the bam file by qname. This is because we want the paired-end reads to be next to each other, so that we can extract them together when we extract allele-specific reads.

One way to sort the bam file is using `Rsamtools` package.

Download `Rsamtools` package.

```{r, eval = F}
source("https://bioconductor.org/biocLite.R")
biocLite("Rsamtools")
```


```{r, eval = F}
library(Rsamtools)
ffi = input_file
ffs = destination_of_sorted_file
sortBam(ffi, fsi, byQname=TRUE, maxMemory=16384)
```
Alternatively, we can directly call samtools.

  + `-n`: by read name
  + `-m`: Maximum memory
  + `-o`: output file
```{bash, eval = F}
Maximum=16384
ffi=input_file
ffs=destination_of_sorted_file

samtools sort -m $maxMemory -n $ffi -o $ffs 

```

### Step 3: extract allele-specific bam file
In phasing and imputation, we created a list of heterozygous SNPs and lift them over to builder hg38. In this step, we will reformat it totab-delimited file with four columns, chromosome, position, allele 1 and allele 2, without header. 

```{bash}
folder_of_sam1='../data/data_snp/sample1'
cd $folder_of_sam1 ;  
cat combined_hg38.txt | cut -f1,3,4,5 | head 
```
Downlad `asSeq` package https://research.fhcrc.org/sun/en/software/asSeq.html

We can get the allele-specific bam file in the following two steps
  
  + `prepareBAM` - Three steps are involved in the preparation. Sorting the bam file by read name, delete those reads that are mapped to multiple places in the genome, and filter out those reads of low quality.
  + `extractAsReads` - A sequence read is counted as allele specific only if it harbors one or more heterozygous genetic markers, and their genotypes are consistent with one and only one of the two haplotypes specified in file snpList.

```{r, eval = F}
library(asSeq)

prepareBAM(input, output_prepareBAM, sortIt=FALSE, filterIt=TRUE, 
           min.avgQ=20, min.mapQ=20, getUniqMapping=TRUE)
           
extractAsReads(paste0(output_prepareBAM, "_uniq_filtered.bam"), tmpSnpFile, outputTag)

```


### Step 4-5: Count allele-specific/total reads 

Count allele-specific reads or total reads using function `summarizeOverlaps` from R package `GenomicAlignments`.

```{r, eval = F}
library("GenomicFeatures")
library("GenomicAlignments")

txdb  = loadDb("Homo_sapiens_gencode_v28_GRCh38.sqlite")
genes = exonsBy(txdb, by="gene")

filenames = list.files(pattern=".bam$")
bamfiles  = BamFileList(filenames, yieldSize=1000000)

se = summarizeOverlaps(features=genes, reads=bamfiles, mode="Union",
             singleEnd=FALSE, ignore.strand=FALSE, fragments=TRUE )

as1 = assay(se)

write.table(as1, file = "gene_level_counts.txt", append = FALSE,
  quote = FALSE, sep = "\t", eol = "\n", row.names = TRUE,
  col.names = TRUE)
```


## Reference: 
  + Shapeit link http://www.shapeit.fr/pages/m03_phasing/imputation.html
  + impute2 link https://mathgen.stats.ox.ac.uk/impute/impute_v2.html
  + liftover link https://genome.ucsc.edu/util.html



